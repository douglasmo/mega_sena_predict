{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script de Exemplo para \"Previsão\" da Mega-Sena usando LSTM - Versão Aprimorada.\n",
    "\n",
    "AVISO FUNDAMENTAL:\n",
    "A Mega-Sena é um jogo de azar. Os sorteios são eventos aleatórios e independentes.\n",
    "Não há NENHUMA EVIDÊNCIA CIENTÍFICA de que resultados passados possam prever\n",
    "resultados futuros. Este script é APENAS UM EXERCÍCIO TÉCNICO de Machine Learning\n",
    "e NÃO DEVE SER USADO como uma ferramenta para escolher números ou esperar ganhos.\n",
    "As previsões, gráficos e métricas geradas refletem o desempenho do modelo nos dados\n",
    "históricos e NÃO indicam capacidade real de previsão futura. USE POR SUA CONTA E RISCO,\n",
    "ENTENDENDO QUE É UM EXPERIMENTO EDUCACIONAL.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # Usaremos para validação, mas teste será cronológico\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Use TensorFlow/Keras para a Rede Neural LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import requests # Para baixar os dados (opcional)\n",
    "from io import StringIO # Para ler os dados baixados\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt # Para gráficos\n",
    "\n",
    "# Ignorar warnings de performance do TensorFlow (opcional)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow')\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "# --- Parâmetros Configuráveis ---\n",
    "DATA_URL = \"https://servicebus2.caixa.gov.br/portaldeloterias/api/megasena/\" # Fonte potencial (verificar formato e disponibilidade)\n",
    "DATA_FILE = None # Defina como None para tentar baixar, ou coloque o caminho do arquivo CSV 'resultados_mega_sena.csv'\n",
    "EXPORT_FILE = 'historico_e_previsoes_megasena.xlsx' # Nome do arquivo Excel para exportação\n",
    "\n",
    "SEQUENCE_LENGTH = 10  # Número de sorteios anteriores a serem usados para prever o próximo\n",
    "NUM_FEATURES = 60     # Números possíveis na Mega-Sena (1 a 60)\n",
    "LSTM_UNITS = 128      # Número de neurônios na camada LSTM\n",
    "DROPOUT_RATE = 0.3    # Taxa de dropout para regularização\n",
    "EPOCHS = 100          # Número máximo de épocas de treinamento\n",
    "BATCH_SIZE = 32       # Tamanho do lote para treinamento\n",
    "TEST_SIZE_RATIO = 0.15 # Proporção do dataset para teste (sorteios mais recentes)\n",
    "\n",
    "# --- Funções (incluindo as de download, preprocessamento, criação de sequências - mantidas da versão anterior) ---\n",
    "\n",
    "def download_and_prepare_data(url=None, file_path=None):\n",
    "    \"\"\"\n",
    "    Baixa os dados da Mega-Sena de uma URL ou carrega de um arquivo CSV local.\n",
    "    Retorna um DataFrame do Pandas com os resultados.\n",
    "    Formato esperado: Colunas com os números sorteados (ex: 'Bola1', 'Bola2', ..., 'Bola6').\n",
    "    \"\"\"\n",
    "    print(\"Carregando dados dos sorteios...\")\n",
    "    df = None\n",
    "\n",
    "    if url:\n",
    "        try:\n",
    "            print(f\"Tentando baixar dados de: {url}\")\n",
    "            response = requests.get(url, verify=False, timeout=30) # Adicionado timeout\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if isinstance(data, list) and data and 'listaDezenas' in data[0]:\n",
    "                 results = []\n",
    "                 concursos = []\n",
    "                 datas = []\n",
    "                 for sorteio in data:\n",
    "                     # Pega apenas as dezenas (e garante que são inteiros)\n",
    "                     dezenas = sorted([int(d) for d in sorteio.get('listaDezenas', [])])\n",
    "                     if len(dezenas) == 6: # Garante que temos 6 dezenas\n",
    "                        results.append(dezenas)\n",
    "                        concursos.append(sorteio.get('numero'))\n",
    "                        datas.append(sorteio.get('dataApuracao'))\n",
    "\n",
    "                 if not results:\n",
    "                     print(\"Nenhum sorteio válido encontrado nos dados baixados.\")\n",
    "                     return None\n",
    "\n",
    "                 df = pd.DataFrame(results, columns=[f'Bola{i+1}' for i in range(6)])\n",
    "                 if concursos: df['Concurso'] = concursos\n",
    "                 if datas: df['Data'] = pd.to_datetime(datas, dayfirst=True)\n",
    "\n",
    "                 # Ordena pelo concurso (mais antigo primeiro) se a coluna existir\n",
    "                 if 'Concurso' in df.columns:\n",
    "                     df = df.sort_values(by='Concurso').reset_index(drop=True)\n",
    "                 elif 'Data' in df.columns:\n",
    "                     df = df.sort_values(by='Data').reset_index(drop=True)\n",
    "\n",
    "                 print(f\"Dados baixados e processados com sucesso ({len(df)} sorteios).\")\n",
    "\n",
    "            else:\n",
    "                 print(\"Formato de dados JSON da API não reconhecido ou inesperado.\")\n",
    "                 # Tenta ler como CSV como fallback (menos provável para APIs modernas)\n",
    "                 try:\n",
    "                     print(\"Tentando ler a resposta como CSV...\")\n",
    "                     df = pd.read_csv(StringIO(response.text))\n",
    "                     print(\"Dados lidos como CSV.\")\n",
    "                 except Exception as e_csv:\n",
    "                     print(f\"Não foi possível interpretar a resposta como JSON ou CSV: {e_csv}\")\n",
    "                     return None # Falha em ambas as tentativas\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erro ao baixar dados: {e}\")\n",
    "            df = None # Garante que df seja None se o download falhar\n",
    "        except Exception as e_proc:\n",
    "             print(f\"Erro ao processar os dados baixados: {e_proc}\")\n",
    "             return None\n",
    "\n",
    "    # Se o download falhou ou não foi tentado, tenta o arquivo local\n",
    "    if df is None and file_path and os.path.exists(file_path):\n",
    "        print(f\"Tentando carregar do arquivo local: {file_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=None, engine='python') # Tenta detectar separador\n",
    "            # Verifica se a detecção funcionou (se temos mais de 1 coluna)\n",
    "            if df.shape[1] < 6:\n",
    "                 print(f\"Arquivo CSV lido, mas parece ter poucas colunas ({df.shape[1]}). Verifique o separador.\")\n",
    "                 # Tenta alguns separadores comuns\n",
    "                 for sep in [';', ',', '\\t']:\n",
    "                     try:\n",
    "                         df_try = pd.read_csv(file_path, sep=sep)\n",
    "                         if df_try.shape[1] >= 6:\n",
    "                             df = df_try\n",
    "                             print(f\"Separador '{sep}' funcionou.\")\n",
    "                             break\n",
    "                     except:\n",
    "                         continue\n",
    "            print(f\"Dados carregados de {file_path}\")\n",
    "        except Exception as e_file:\n",
    "            print(f\"Erro ao carregar arquivo local: {e_file}\")\n",
    "            return None\n",
    "\n",
    "    # Se ainda não temos DataFrame, sai\n",
    "    if df is None:\n",
    "        print(\"Nenhuma fonte de dados (URL ou arquivo) funcionou ou foi fornecida.\")\n",
    "        return None\n",
    "\n",
    "    # --- Bloco de identificação e renomeação de colunas (aprimorado) ---\n",
    "    bola_cols_found = []\n",
    "    potential_col_names = [f'Bola{i+1}' for i in range(6)] + \\\n",
    "                          [f'bola{i+1}' for i in range(6)] + \\\n",
    "                          [f'Dezena{i+1}' for i in range(6)] + \\\n",
    "                          [f'dezena{i+1}' for i in range(6)] + \\\n",
    "                          [f'N{i+1}' for i in range(6)] # Adiciona mais padrões\n",
    "\n",
    "    # Prioriza nomes exatos ou variações comuns\n",
    "    for pattern_list in [[f'Bola{i+1}' for i in range(6)], [f'Dezena{i+1}' for i in range(6)]]:\n",
    "        if all(col in df.columns for col in pattern_list):\n",
    "            bola_cols_found = pattern_list\n",
    "            break\n",
    "\n",
    "    # Se não encontrou, tenta identificar heuristicamente\n",
    "    if not bola_cols_found:\n",
    "        numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "        potential_bola_cols = [c for c in numeric_cols if df[c].between(1, 60, inclusive='both').all() and df[c].notna().all()]\n",
    "        if len(potential_bola_cols) >= 6:\n",
    "            # Pega as primeiras 6 colunas que se encaixam no critério\n",
    "            bola_cols_found = potential_bola_cols[:6]\n",
    "            print(f\"Colunas de bolas identificadas heuristicamente como: {bola_cols_found}\")\n",
    "        else:\n",
    "            print(f\"Erro: Não foi possível identificar 6 colunas com números entre 1 e 60.\")\n",
    "            print(f\"Colunas encontradas: {list(df.columns)}\")\n",
    "            return None\n",
    "\n",
    "    # Renomeia para o padrão 'BolaX' se necessário e seleciona\n",
    "    rename_map = {found_col: f'Bola{i+1}' for i, found_col in enumerate(bola_cols_found)}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "    bola_cols = [f'Bola{i+1}' for i in range(6)]\n",
    "\n",
    "    # Garante que as colunas das bolas são numéricas inteiras\n",
    "    try:\n",
    "        for col in bola_cols:\n",
    "            df[col] = pd.to_numeric(df[col]).astype(int)\n",
    "        print(\"Colunas das bolas verificadas e convertidas para inteiro.\")\n",
    "    except Exception as e_num:\n",
    "        print(f\"Erro ao converter colunas de bolas para numérico: {e_num}\")\n",
    "        return None\n",
    "\n",
    "    # Seleciona e retorna apenas as colunas relevantes (Bolas e talvez Concurso/Data para referência)\n",
    "    cols_to_keep = bola_cols\n",
    "    if 'Concurso' in df.columns: cols_to_keep.append('Concurso')\n",
    "    if 'Data' in df.columns: cols_to_keep.append('Data')\n",
    "\n",
    "    final_df = df[cols_to_keep].copy()\n",
    "\n",
    "    # Ordena novamente para garantir, caso a ordenação original tenha se perdido\n",
    "    if 'Concurso' in final_df.columns:\n",
    "        final_df = final_df.sort_values(by='Concurso').reset_index(drop=True)\n",
    "    elif 'Data' in final_df.columns:\n",
    "        final_df = final_df.sort_values(by='Data').reset_index(drop=True)\n",
    "\n",
    "    print(f\"Total de {len(final_df)} sorteios carregados e formatados.\")\n",
    "    return final_df # Retorna o DataFrame com Bolas e possivelmente Concurso/Data\n",
    "\n",
    "\n",
    "def preprocess_data(df_balls_only):\n",
    "    \"\"\"\n",
    "    Transforma os números sorteados (DataFrame apenas com colunas BolaX)\n",
    "    em formato MultiLabelBinarizer (One-Hot Encoding para múltiplas labels).\n",
    "    \"\"\"\n",
    "    print(\"Pré-processando os dados (codificação One-Hot)...\")\n",
    "    draws_list = df_balls_only.values.tolist()\n",
    "    mlb = MultiLabelBinarizer(classes=list(range(1, NUM_FEATURES + 1)))\n",
    "    encoded_data = mlb.fit_transform(draws_list)\n",
    "    print(f\"Dados transformados em formato binário ({encoded_data.shape[1]} features).\")\n",
    "    return encoded_data, mlb\n",
    "\n",
    "def create_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Cria sequências de dados para o modelo LSTM.\n",
    "    X: Sequências de 'sequence_length' sorteios.\n",
    "    y: O sorteio seguinte a cada sequência.\n",
    "    \"\"\"\n",
    "    print(f\"Criando sequências de tamanho {sequence_length}...\")\n",
    "    X, y = [], []\n",
    "    if len(data) <= sequence_length:\n",
    "        print(f\"Erro: Não há dados suficientes ({len(data)}) para criar sequências de tamanho {sequence_length}.\")\n",
    "        return np.array([]), np.array([])\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:(i + sequence_length)])\n",
    "        y.append(data[i + sequence_length])\n",
    "    print(f\"{len(X)} sequências criadas.\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_lstm_model(sequence_length, num_features, lstm_units=128, dropout_rate=0.3):\n",
    "    \"\"\" Constrói o modelo LSTM. \"\"\"\n",
    "    print(\"Construindo o modelo LSTM...\")\n",
    "    model = Sequential(name=\"Modelo_LSTM_MegaSena\")\n",
    "    model.add(Input(shape=(sequence_length, num_features)))\n",
    "    model.add(LSTM(lstm_units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_units // 2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_features, activation='sigmoid')) # Saída multi-label\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['binary_accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):\n",
    "    \"\"\" Treina o modelo LSTM com EarlyStopping e ReduceLROnPlateau. \"\"\"\n",
    "    print(\"Iniciando o treinamento do modelo...\")\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.0001, verbose=1)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Treinamento concluído.\")\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, batch_size=32):\n",
    "    \"\"\" Avalia o modelo no conjunto de teste. \"\"\"\n",
    "    print(\"\\nAvaliando o modelo no conjunto de teste...\")\n",
    "    results = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0) # verbose=0 para não poluir\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Loss no Teste: {results[0]:.4f}\")\n",
    "    print(f\"Binary Accuracy no Teste: {results[1]:.4f}\")\n",
    "    if len(results) > 2: print(f\"AUC no Teste: {results[2]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Lembre-se: Métricas refletem o ajuste aos dados históricos, não previsão real.\")\n",
    "    print(\"-\" * 30)\n",
    "    return results\n",
    "\n",
    "def predict_next_draw(model, last_sequence, mlb, num_predictions=6):\n",
    "    \"\"\" Faz a previsão para o próximo sorteio. \"\"\"\n",
    "    print(\"\\nFazendo a previsão para o PRÓXIMO sorteio...\")\n",
    "    last_sequence_batch = np.expand_dims(last_sequence, axis=0)\n",
    "    predicted_probabilities = model.predict(last_sequence_batch)[0]\n",
    "    predicted_indices = np.argsort(predicted_probabilities)[-num_predictions:]\n",
    "    predicted_numbers = sorted((predicted_indices + 1).tolist()) # Adiciona 1 para obter número real\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Previsão dos {num_predictions} números mais prováveis (baseado no histórico):\")\n",
    "    print(predicted_numbers)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Probabilidades estimadas para os números previstos:\")\n",
    "    for num_idx in predicted_indices:\n",
    "        print(f\"  Número {num_idx+1}: {predicted_probabilities[num_idx]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"AVISO: Esta previsão é um exercício técnico. NÃO HÁ GARANTIA DE ACERTO.\")\n",
    "    print(\"-\" * 30)\n",
    "    return predicted_numbers, predicted_probabilities\n",
    "\n",
    "# --- Novas Funções de Visualização ---\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\" Plota o histórico de treinamento (loss e AUC). \"\"\"\n",
    "    if not history or not history.history:\n",
    "        print(\"Histórico de treinamento não disponível para plotar.\")\n",
    "        return\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-darkgrid') # Estilo do gráfico\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Gráfico da Loss (Perda)\n",
    "    if 'loss' in history.history and 'val_loss' in history.history:\n",
    "        axes[0].plot(history.history['loss'], label='Loss Treinamento')\n",
    "        axes[0].plot(history.history['val_loss'], label='Loss Validação')\n",
    "        axes[0].set_title('Histórico da Função de Perda')\n",
    "        axes[0].set_xlabel('Época')\n",
    "        axes[0].set_ylabel('Loss (Binary Crossentropy)')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "\n",
    "    # Gráfico da AUC (ou métrica principal)\n",
    "    metric_key = 'auc' # Prioriza AUC\n",
    "    val_metric_key = 'val_auc'\n",
    "    if metric_key not in history.history or val_metric_key not in history.history:\n",
    "         metric_key = 'binary_accuracy' # Fallback para accuracy\n",
    "         val_metric_key = 'val_binary_accuracy'\n",
    "\n",
    "    if metric_key in history.history and val_metric_key in history.history:\n",
    "        axes[1].plot(history.history[metric_key], label=f'{metric_key.capitalize()} Treinamento')\n",
    "        axes[1].plot(history.history[val_metric_key], label=f'{metric_key.capitalize()} Validação')\n",
    "        axes[1].set_title(f'Histórico da Métrica ({metric_key.capitalize()})')\n",
    "        axes[1].set_xlabel('Época')\n",
    "        axes[1].set_ylabel(metric_key.capitalize())\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "    else:\n",
    "        # Se nenhuma métrica principal foi encontrada, remove o segundo subplot\n",
    "        fig.delaxes(axes[1])\n",
    "        fig.set_size_inches(8, 5) # Ajusta tamanho se for só um gráfico\n",
    "\n",
    "\n",
    "    plt.suptitle(\"Desempenho do Modelo Durante o Treinamento\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajusta layout para o supertítulo\n",
    "\n",
    "\n",
    "def plot_prediction_distribution(predicted_probabilities, predicted_numbers):\n",
    "    \"\"\" Plota a distribuição de probabilidade da previsão final. \"\"\"\n",
    "    if predicted_probabilities is None or len(predicted_probabilities) != NUM_FEATURES:\n",
    "        print(\"Probabilidades de previsão inválidas para plotar.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    numbers = np.arange(1, NUM_FEATURES + 1)\n",
    "    colors = ['red' if n in predicted_numbers else 'skyblue' for n in numbers]\n",
    "    bars = plt.bar(numbers, predicted_probabilities, color=colors)\n",
    "\n",
    "    plt.xlabel(\"Número da Mega-Sena\")\n",
    "    plt.ylabel(\"Probabilidade Estimada (Sigmoid Output)\")\n",
    "    plt.title(\"Distribuição de Probabilidade Estimada para o Próximo Sorteio\")\n",
    "    plt.xticks(np.arange(0, NUM_FEATURES + 1, 5)) # Marcações a cada 5 números\n",
    "    plt.xlim(0, NUM_FEATURES + 1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Adiciona legenda improvisada para as cores\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='red', edgecolor='red', label='Top 6 Previstos'),\n",
    "                       Patch(facecolor='skyblue', edgecolor='skyblue', label='Outros Números')]\n",
    "    plt.legend(handles=legend_elements)\n",
    "\n",
    "\n",
    "def plot_hits_over_time(model, X_test, y_test, mlb):\n",
    "    \"\"\"\n",
    "    Plota o número de acertos (números sorteados que estavam entre os 6 mais prováveis\n",
    "    previstos pelo modelo) para cada sorteio no conjunto de teste.\n",
    "    \"\"\"\n",
    "    if X_test is None or y_test is None or X_test.shape[0] == 0:\n",
    "        print(\"Dados de teste insuficientes para plotar acertos ao longo do tempo.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nCalculando acertos no conjunto de teste (histórico)...\")\n",
    "    y_pred_probs_test = model.predict(X_test)\n",
    "    hits_per_draw = []\n",
    "\n",
    "    for i in range(len(y_pred_probs_test)):\n",
    "        pred_probs = y_pred_probs_test[i]\n",
    "        actual_encoded = y_test[i]\n",
    "\n",
    "        # Índices dos 6 números com maior probabilidade prevista\n",
    "        top6_pred_indices = np.argsort(pred_probs)[-6:]\n",
    "\n",
    "        # Índices dos números que realmente foram sorteados\n",
    "        actual_winning_indices = np.where(actual_encoded == 1)[0]\n",
    "\n",
    "        # Calcula a interseção (quantos números previstos estavam corretos)\n",
    "        num_hits = len(set(top6_pred_indices) & set(actual_winning_indices))\n",
    "        hits_per_draw.append(num_hits)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(hits_per_draw, marker='o', linestyle='-', markersize=4, label='Nº de Acertos por Sorteio no Teste')\n",
    "    plt.xlabel(\"Índice do Sorteio no Conjunto de Teste (Ordem Cronológica)\")\n",
    "    plt.ylabel(\"Número de Acertos (entre os Top 6 previstos)\")\n",
    "    plt.title(\"Número de Acertos do Modelo no Conjunto de Teste Histórico\")\n",
    "    plt.yticks(np.arange(0, 7, 1)) # Eixo Y de 0 a 6 acertos\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Calcula e exibe estatísticas básicas de acertos\n",
    "    avg_hits = np.mean(hits_per_draw)\n",
    "    max_hits = np.max(hits_per_draw)\n",
    "    print(f\"\\nEstatísticas de Acertos no Conjunto de Teste ({len(X_test)} sorteios):\")\n",
    "    print(f\" - Média de acertos por sorteio: {avg_hits:.3f}\")\n",
    "    print(f\" - Máximo de acertos em um sorteio: {max_hits}\")\n",
    "    for i in range(max_hits + 1):\n",
    "        count = hits_per_draw.count(i)\n",
    "        print(f\" - Sorteios com {i} acerto(s): {count} ({count/len(hits_per_draw)*100:.1f}%)\")\n",
    "    print(\"Lembre-se: Acertos passados não garantem acertos futuros.\")\n",
    "\n",
    "\n",
    "# --- Nova Função de Exportação ---\n",
    "\n",
    "def export_predictions_to_excel(model, X, df_original, sequence_length, mlb, filename=\"mega_sena_predictions.xlsx\"):\n",
    "    \"\"\"\n",
    "    Gera previsões para todos os dados sequenciados (X) e exporta para Excel\n",
    "    junto com os resultados reais correspondentes.\n",
    "    \"\"\"\n",
    "    print(f\"\\nGerando previsões para exportação para o arquivo: {filename}...\")\n",
    "    if X is None or X.shape[0] == 0:\n",
    "        print(\"Não há sequências (X) para gerar previsões para exportação.\")\n",
    "        return\n",
    "\n",
    "    # 1. Fazer previsões para todas as sequências em X\n",
    "    all_pred_probs = model.predict(X, batch_size=BATCH_SIZE) # (num_sequences, 60)\n",
    "\n",
    "    # 2. Preparar DataFrame de probabilidades\n",
    "    prob_cols = [f'Prob_{i+1}' for i in range(NUM_FEATURES)]\n",
    "    probs_df = pd.DataFrame(all_pred_probs, columns=prob_cols)\n",
    "\n",
    "    # 3. Identificar os Top 6 previstos para cada linha\n",
    "    top_6_preds = []\n",
    "    for i in range(len(all_pred_probs)):\n",
    "        top_indices = np.argsort(all_pred_probs[i])[-6:]\n",
    "        top_numbers = sorted((top_indices + 1).tolist()) # Números reais (1-60)\n",
    "        top_6_preds.append(top_numbers)\n",
    "\n",
    "    pred_cols = [f'Pred_{i+1}' for i in range(6)]\n",
    "    preds_df = pd.DataFrame(top_6_preds, columns=pred_cols)\n",
    "\n",
    "    # 4. Obter os resultados reais correspondentes às previsões\n",
    "    # A previsão para X[i] corresponde ao sorteio original em df_original.iloc[i + sequence_length]\n",
    "    start_index_actual = sequence_length\n",
    "    end_index_actual = sequence_length + len(X)\n",
    "    actual_results_df = df_original.iloc[start_index_actual:end_index_actual].reset_index(drop=True)\n",
    "\n",
    "    # Mantém apenas as colunas originais relevantes (Concurso, Data, Bolas) se existirem\n",
    "    actual_cols_to_keep = [col for col in ['Concurso', 'Data'] if col in actual_results_df.columns] + \\\n",
    "                          [f'Bola{i+1}' for i in range(6)]\n",
    "    actual_results_df = actual_results_df[actual_cols_to_keep]\n",
    "\n",
    "    # 5. Combinar os DataFrames: Reais | Preditos (Top 6) | Probabilidades (Todas)\n",
    "    final_export_df = pd.concat([actual_results_df, preds_df, probs_df], axis=1)\n",
    "\n",
    "    # 6. Exportar para Excel\n",
    "    try:\n",
    "        final_export_df.to_excel(filename, index=False, engine='openpyxl')\n",
    "        print(f\"Dados exportados com sucesso para '{filename}'.\")\n",
    "        print(f\" - O arquivo contém {len(final_export_df)} linhas.\")\n",
    "        print(f\" - Cada linha mostra o resultado real e a previsão do modelo para aquele sorteio.\")\n",
    "    except ImportError:\n",
    "        print(\"\\nAVISO: Para exportar para Excel (.xlsx), a biblioteca 'openpyxl' é necessária.\")\n",
    "        print(\"Instale com: pip install openpyxl\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro ao exportar para Excel: {e}\")\n",
    "\n",
    "\n",
    "# --- Fluxo Principal Atualizado ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Carregar Dados\n",
    "    df_full = download_and_prepare_data(url=DATA_URL, file_path=DATA_FILE)\n",
    "\n",
    "    if df_full is not None and not df_full.empty:\n",
    "        # Extrai apenas as colunas das bolas para pré-processamento\n",
    "        bola_cols = [f'Bola{i+1}' for i in range(6)]\n",
    "        df_balls = df_full[bola_cols]\n",
    "\n",
    "        # 2. Pré-processamento (One-Hot Encoding)\n",
    "        encoded_data, mlb = preprocess_data(df_balls)\n",
    "\n",
    "        if encoded_data.shape[0] > SEQUENCE_LENGTH:\n",
    "            # 3. Criar Sequências\n",
    "            X, y = create_sequences(encoded_data, SEQUENCE_LENGTH)\n",
    "\n",
    "            if X.shape[0] > 0:\n",
    "                # 4. Dividir em Treino, Validação e Teste (CRONOLOGICAMENTE)\n",
    "                # Teste são os dados mais recentes\n",
    "                test_split_index = int(len(X) * (1 - TEST_SIZE_RATIO))\n",
    "                X_temp, X_test = X[:test_split_index], X[test_split_index:]\n",
    "                y_temp, y_test = y[:test_split_index], y[test_split_index:]\n",
    "\n",
    "                # Divide o restante em Treino e Validação (aleatório ou cronológico)\n",
    "                # Usar train_test_split para validação é comum, mas para séries temporais\n",
    "                # uma divisão cronológica pode ser mais rigorosa. Vamos manter o split aleatório\n",
    "                # para validação aqui, mas o teste é estritamente cronológico.\n",
    "                val_size = 0.15 # 15% do que sobrou para validação\n",
    "                if len(X_temp) > 1: # Precisa de pelo menos 2 amostras para dividir\n",
    "                    X_train, X_val, y_train, y_val = train_test_split(\n",
    "                        X_temp, y_temp, test_size=val_size, random_state=42, shuffle=False # shuffle=False para manter ordem local\n",
    "                    )\n",
    "                else: # Não há dados suficientes para validação separada\n",
    "                     X_train, y_train = X_temp, y_temp\n",
    "                     X_val, y_val = X_test, y_test # Usa teste como validação (não ideal, mas evita erro)\n",
    "                     print(\"\\nAviso: Poucos dados para conjunto de validação separado. Usando conjunto de teste para validação.\")\n",
    "\n",
    "\n",
    "                print(f\"\\nDados divididos em:\")\n",
    "                print(f\" - Treino:    {len(X_train)} sequências\")\n",
    "                print(f\" - Validação: {len(X_val)} sequências\")\n",
    "                print(f\" - Teste:     {len(X_test)} sequências (mais recentes)\")\n",
    "\n",
    "                # 5. Construir o Modelo\n",
    "                model = build_lstm_model(SEQUENCE_LENGTH, NUM_FEATURES, LSTM_UNITS, DROPOUT_RATE)\n",
    "\n",
    "                # 6. Treinar o Modelo\n",
    "                history = train_model(model, X_train, y_train, X_val, y_val, EPOCHS, BATCH_SIZE)\n",
    "\n",
    "                # --- PLOT 1: Histórico de Treinamento ---\n",
    "                plot_training_history(history)\n",
    "\n",
    "                # 7. Avaliar o Modelo (no conjunto de teste histórico)\n",
    "                evaluation_results = evaluate_model(model, X_test, y_test, BATCH_SIZE)\n",
    "\n",
    "                # --- PLOT 2: Acertos ao Longo do Tempo (no Teste) ---\n",
    "                plot_hits_over_time(model, X_test, y_test, mlb)\n",
    "\n",
    "                # 8. Fazer a Previsão para o Próximo Sorteio\n",
    "                last_sequence_input = encoded_data[-SEQUENCE_LENGTH:]\n",
    "                if last_sequence_input.shape[0] == SEQUENCE_LENGTH:\n",
    "                     predicted_numbers, predicted_probabilities = predict_next_draw(model, last_sequence_input, mlb, num_predictions=6)\n",
    "\n",
    "                     # --- PLOT 3: Distribuição da Previsão Final ---\n",
    "                     plot_prediction_distribution(predicted_probabilities, predicted_numbers)\n",
    "\n",
    "                else:\n",
    "                     print(\"\\nNão foi possível obter a última sequência para previsão final (dados insuficientes).\")\n",
    "                     predicted_probabilities = None # Garante que não tentará plotar\n",
    "\n",
    "                # 9. Exportar Histórico e Previsões para Excel\n",
    "                # Usa todas as sequências X (treino+val+teste) para gerar o histórico completo de previsões\n",
    "                export_predictions_to_excel(model, X, df_full, SEQUENCE_LENGTH, mlb, filename=EXPORT_FILE)\n",
    "\n",
    "                # Exibe todos os gráficos gerados\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                print(\"\\nNão foi possível criar sequências a partir dos dados.\")\n",
    "        else:\n",
    "             print(f\"\\nDataset muito pequeno ({encoded_data.shape[0]} sorteios) para a sequência de tamanho {SEQUENCE_LENGTH}.\")\n",
    "    else:\n",
    "        print(\"\\nNão foi possível carregar ou processar os dados da Mega-Sena. Encerrando.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# PrevisÃ£o da Mega-Sena com LSTM

Este projeto implementa um modelo de deep learning usando LSTM (Long Short-Term Memory) para analisar e prever nÃºmeros da Mega-Sena. O modelo Ã© treinado com dados histÃ³ricos dos sorteios e utiliza tÃ©cnicas avanÃ§adas de processamento de sequÃªncias temporais.

## CaracterÃ­sticas

- Download automÃ¡tico de dados histÃ³ricos da Mega-Sena
- PrÃ©-processamento e normalizaÃ§Ã£o dos dados
- Modelo LSTM com arquitetura otimizada
- Sistema de cache para evitar downloads repetidos
- VisualizaÃ§Ãµes detalhadas do treinamento e previsÃµes
- ExportaÃ§Ã£o de resultados em Excel
- Logging completo para rastreamento de erros
- ConfiguraÃ§Ã£o flexÃ­vel via arquivo JSON

## Requisitos

- Python 3.8+
- Bibliotecas Python (instaladas via `pip install -r requirements.txt`):
  - numpy
  - pandas
  - tensorflow
  - scikit-learn
  - matplotlib
  - openpyxl
  - requests

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/mega-sena.git
cd mega-sena
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

3. Configure o arquivo `config.json` conforme necessÃ¡rio (um exemplo Ã© fornecido)

## Uso

Execute o script principal:
```bash
python mega_sena.py
```

O programa irÃ¡:
1. Baixar os dados histÃ³ricos (ou usar cache se disponÃ­vel)
2. Treinar o modelo LSTM
3. Gerar previsÃµes para o prÃ³ximo sorteio
4. Criar visualizaÃ§Ãµes
5. Exportar resultados em Excel

## Arquivos Gerados

- `historico_e_previsoes_megasena.xlsx`: Resultados detalhados em Excel
- `training_history.png`: GrÃ¡ficos do histÃ³rico de treinamento
- `prediction_analysis.png`: AnÃ¡lise visual das previsÃµes
- `mega_sena.log`: Log detalhado da execuÃ§Ã£o

## Estrutura do Projeto

```
mega_sena/
â”œâ”€â”€ mega_sena.py          # Script principal
â”œâ”€â”€ config.json           # ConfiguraÃ§Ãµes do modelo
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â”œâ”€â”€ README.md            # Este arquivo
â””â”€â”€ cache/               # DiretÃ³rio para cache de dados
```

## ConfiguraÃ§Ã£o

O arquivo `config.json` permite ajustar vÃ¡rios parÃ¢metros:

```json
{
    "data_url": "https://loteriascaixa-api.herokuapp.com/api/megasena",
    "data_file": null,
    "export_file": "historico_e_previsoes_megasena.xlsx",
    "sequence_length": 10,
    "num_features": 60,
    "lstm_units": 128,
    "dropout_rate": 0.3,
    "epochs": 100,
    "batch_size": 32,
    "test_size_ratio": 0.15,
    "cache_duration_hours": 24,
    "cache_dir": "cache"
}
```

## ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, sinta-se Ã  vontade para:
1. Fazer um fork do projeto
2. Criar uma branch para sua feature
3. Fazer commit das mudanÃ§as
4. Abrir um Pull Request

## LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## Contato

Se vocÃª tiver dÃºvidas ou sugestÃµes, por favor abra uma issue no GitHub. 


Claro! VocÃª montou um **projeto muito bem estruturado** e profissional, parabÃ©ns! Agora vamos fazer uma aula detalhada e didÃ¡tica sobre como o **LSTM estÃ¡ sendo usado para prever nÃºmeros da Mega-Sena** nesse seu projeto.

---

## ğŸ§  **AULA EXPLICATIVA: Como o LSTM estÃ¡ sendo usado na previsÃ£o da Mega-Sena**

---

### ğŸ“Œ 1. **O que Ã© LSTM (Long Short-Term Memory)?**

**LSTM** Ã© um tipo de rede neural recorrente (RNN) especialmente eficaz para **sequÃªncias temporais**.  
Ela Ã© capaz de **"lembrar" informaÃ§Ãµes importantes ao longo do tempo**, filtrando o que esquecer e o que manter, diferente das RNNs tradicionais.

> **Exemplo de uso clÃ¡ssico:** PrevisÃ£o de sÃ©ries temporais, traduÃ§Ã£o automÃ¡tica, reconhecimento de fala, etc.

---

### ğŸ¯ **No seu projeto, a LSTM estÃ¡ sendo usada para prever o PRÃ“XIMO sorteio da Mega-Sena com base em sorteios anteriores.**

---

## ğŸ“¦ 2. **Como os dados sÃ£o estruturados**

Imagine a Mega-Sena como uma **sÃ©rie de eventos temporais**: cada sorteio Ã© um momento no tempo, com 6 dezenas sorteadas.

### âœ… Etapas de preparaÃ§Ã£o:

#### ğŸ”¹ a) One-Hot Encoding com `MultiLabelBinarizer`
Cada sorteio Ã© transformado em um vetor de 60 posiÃ§Ãµes (nÃºmeros de 1 a 60):
- Se o nÃºmero 5 foi sorteado, a posiÃ§Ã£o 5 recebe `1`.
- Se o nÃºmero 23 **nÃ£o** foi sorteado, a posiÃ§Ã£o 23 recebe `0`.

Exemplo:
```text
Sorteio: [5, 12, 18, 33, 45, 60]
Vetor:   [0, 0, 0, 0, 1, ..., 1]  â† 60 posiÃ§Ãµes
```

---

#### ğŸ”¹ b) SequÃªncia de entrada (X) e alvo (y)

VocÃª usa uma **janela deslizante** para construir as sequÃªncias de entrada.  
Exemplo com `sequence_length = 3`:

| Entrada (X)                                       | Alvo (y)              |
|--------------------------------------------------|-----------------------|
| Sorteios 1, 2, 3 (3 vetores de 60 bits)          | Sorteio 4 (vetor)     |
| Sorteios 2, 3, 4                                  | Sorteio 5             |
| ...                                              | ...                   |

Assim, o LSTM aprende **padrÃµes de como as dezenas evoluem** ao longo do tempo.

---

## ğŸ—ï¸ 3. **A Estrutura do Modelo LSTM**

No seu cÃ³digo, a funÃ§Ã£o `build_lstm_model()` cria o modelo assim:

```python
model = Sequential()
model.add(Input(shape=(sequence_length, num_features)))  # Ex: (30, 60)
model.add(LSTM(128, return_sequences=True))              # Primeira camada LSTM
model.add(Dropout(0.3))
model.add(LSTM(64))                                      # Segunda camada LSTM
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))                  # Camada densa intermediÃ¡ria
model.add(Dense(60, activation='sigmoid'))               # SaÃ­da com 60 probabilidades
```

### ğŸ§© InterpretaÃ§Ã£o:
- **Input:** SequÃªncia de 30 sorteios anteriores (cada um com 60 bits).
- **LSTM:** Processa a sequÃªncia e "lembra" de padrÃµes.
- **Dense final:** Calcula a **probabilidade de cada nÃºmero (1 a 60)** aparecer no prÃ³ximo sorteio.

---

## ğŸ§® 4. **Como Ã© feita a previsÃ£o**

ApÃ³s o treinamento:

- O modelo recebe a **Ãºltima sequÃªncia de sorteios (X[-1])**
- Retorna 60 probabilidades (sigmoid output entre 0 e 1)
- Os **6 nÃºmeros com maiores probabilidades** sÃ£o selecionados como a "previsÃ£o"

Exemplo:
```python
predicted_indices = np.argsort(probabilidades)[-6:]
predicted_numbers = sorted((predicted_indices + 1).tolist())
```

---

## ğŸ“ˆ 5. **AvaliaÃ§Ã£o real do modelo**

VocÃª avalia o desempenho de duas formas:

### âœ”ï¸ AvaliaÃ§Ã£o TÃ©cnica:
- `Loss`: Erro da previsÃ£o (funÃ§Ã£o de perda binÃ¡ria)
- `Binary Accuracy`: Quantos bits acertou
- `AUC`: QuÃ£o bem o modelo diferencia 1s de 0s (nÃºmeros sorteados ou nÃ£o)

### âœ”ï¸ AvaliaÃ§Ã£o PrÃ¡tica (mais Ãºtil!):
- Compara os 6 nÃºmeros previstos com os sorteados reais
- Conta quantos acertos o modelo teve por sorteio
- Mostra a mÃ©dia e distribuiÃ§Ã£o de acertos

---

## ğŸ§ª 6. **LimitaÃ§Ãµes importantes**

- A Mega-Sena Ã© **aleatÃ³ria por definiÃ§Ã£o** (em teoria).
- Mesmo com redes neurais, nÃ£o hÃ¡ garantia de prever corretamente.
- Esse projeto Ã© **um exercÃ­cio de Machine Learning**, nÃ£o uma ferramenta infalÃ­vel para ganhar na loteria.

---

## âœ… ConclusÃ£o

| Etapa | O que faz |
|-------|-----------|
| 1. PrÃ©-processamento | Transforma sorteios em vetores binÃ¡rios |
| 2. CriaÃ§Ã£o das sequÃªncias | ConstrÃ³i X (entrada) e y (alvo) |
| 3. Modelo LSTM | Aprende padrÃµes temporais nos sorteios |
| 4. PrevisÃ£o | Gera 60 probabilidades, escolhe os 6 maiores |
| 5. AvaliaÃ§Ã£o | Mede acertos reais + mÃ©tricas de aprendizado |

---

# PrevisÃ£o da Mega-Sena com GRU

Este projeto implementa um modelo de deep learning usando GRU (Gated Recurrent Unit) para analisar e prever nÃºmeros da Mega-Sena. O modelo Ã© treinado com dados histÃ³ricos dos sorteios e utiliza tÃ©cnicas avanÃ§adas de processamento de sequÃªncias temporais, incluindo features estatÃ­sticas e temporais.

## CaracterÃ­sticas

- Download automÃ¡tico de dados histÃ³ricos da Mega-Sena
- PrÃ©-processamento e normalizaÃ§Ã£o dos dados
- Modelo GRU com arquitetura otimizada e Batch Normalization
- Features estatÃ­sticas avanÃ§adas (paridade, soma, range, zonas, frequÃªncia rolante)
- Features temporais (sorteios desde Ãºltima apariÃ§Ã£o)
- Sistema de cache para evitar downloads repetidos
- VisualizaÃ§Ãµes detalhadas do treinamento e previsÃµes
- ExportaÃ§Ã£o de resultados em Excel
- Logging completo para rastreamento de erros
- ConfiguraÃ§Ã£o flexÃ­vel via arquivo JSON
- Suporte a TensorBoard para monitoramento do treinamento
- OtimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros

## Requisitos

- Python 3.8+
- Bibliotecas Python (instaladas via `pip install -r requirements.txt`):
  - numpy
  - pandas
  - tensorflow
  - scikit-learn
  - matplotlib
  - openpyxl
  - requests
  - tqdm

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/mega-sena.git
cd mega-sena
```

2. Configure o ambiente virtual e instale as dependÃªncias (Windows):
```bash
setup_env.bat
```

Ou manualmente:
```bash
python -m venv .env
source .env/bin/activate  # Linux/Mac
.env\Scripts\activate     # Windows
pip install -r requirements.txt
```

3. Configure o arquivo `configv3.json` conforme necessÃ¡rio (um exemplo Ã© fornecido)

## Uso

### Usando menus (Windows)
Execute o arquivo batch e siga as instruÃ§Ãµes:
```bash
run_mega_sena.bat
```

### Linha de comando
```bash
# ExecuÃ§Ã£o normal
python run_mega_sena.py

# Teste de hiperparÃ¢metros com Grid Search
python run_mega_sena.py --test-hyperparameters --method grid

# Teste de hiperparÃ¢metros com Random Search (ex: 15 iteraÃ§Ãµes)
python run_mega_sena.py --test-hyperparameters --method random --iterations 15
```

O programa irÃ¡:
1. Baixar os dados histÃ³ricos (ou usar cache se disponÃ­vel)
2. Calcular features estatÃ­sticas e temporais
3. Treinar o modelo GRU (ou otimizar hiperparÃ¢metros se solicitado)
4. Gerar previsÃµes para o prÃ³ximo sorteio
5. Criar visualizaÃ§Ãµes
6. Exportar resultados em Excel

## OtimizaÃ§Ã£o de HiperparÃ¢metros

O sistema permite buscar automaticamente a melhor configuraÃ§Ã£o de hiperparÃ¢metros:

1. **Grid Search**: Testa todas as combinaÃ§Ãµes possÃ­veis de parÃ¢metros
2. **Random Search**: Testa um subconjunto aleatÃ³rio de combinaÃ§Ãµes

Os hiperparÃ¢metros testÃ¡veis incluem:
- Tamanho da sequÃªncia (`sequence_length`)
- Unidades GRU (`gru_units`)
- Taxa de dropout (`dropout_rate`)
- Uso de Batch Normalization (`use_batch_norm`)
- Tamanho do batch (`batch_size`)

Configure os parÃ¢metros a serem testados no arquivo `configv3.json`:

```json
"hyperparameter_search": {
    "method": "grid",
    "n_iterations": 20,
    "param_grid": {
        "sequence_length": [10, 15, 20, 25],
        "gru_units": [128, 192, 256, 320],
        ...
    }
}
```

## Arquivos Gerados

- `historico_e_previsoes_megasena_v3.xlsx`: Resultados detalhados em Excel
- `training_history_v3.png`: GrÃ¡ficos do histÃ³rico de treinamento
- `prediction_analysis_v3.png`: AnÃ¡lise visual das previsÃµes
- `hits_over_time_v3.png`: GrÃ¡fico de acertos ao longo do tempo
- `mega_sena_v3.log`: Log detalhado da execuÃ§Ã£o
- `logs/fit/`: DiretÃ³rio com logs do TensorBoard
- `hyperparameter_results.xlsx`: Resultados da otimizaÃ§Ã£o de hiperparÃ¢metros
- `hyperparameter_analysis.png`: AnÃ¡lise grÃ¡fica dos hiperparÃ¢metros
- `top_hyperparameters.png`: GrÃ¡fico das melhores configuraÃ§Ãµes

## Estrutura do Projeto

```
mega_sena/
â”œâ”€â”€ mega_sena_v3.py      # Script principal
â”œâ”€â”€ hyperparameter_tuning.py # MÃ³dulo de otimizaÃ§Ã£o de hiperparÃ¢metros
â”œâ”€â”€ configv3.json        # ConfiguraÃ§Ãµes do modelo
â”œâ”€â”€ run_mega_sena.py     # Script para execuÃ§Ã£o via terminal
â”œâ”€â”€ run_mega_sena.bat    # Script para execuÃ§Ã£o via Windows
â”œâ”€â”€ setup_env.bat        # Script para configurar ambiente virtual
â”œâ”€â”€ requirements.txt     # DependÃªncias do projeto
â”œâ”€â”€ README.md            # Este arquivo
â”œâ”€â”€ .env/                # Ambiente virtual Python
â”œâ”€â”€ output/              # DiretÃ³rio para arquivos de saÃ­da
â”œâ”€â”€ cache/               # DiretÃ³rio para cache de dados
â””â”€â”€ logs/                # DiretÃ³rio para logs do TensorBoard
```

## ConfiguraÃ§Ã£o

O arquivo `configv3.json` permite ajustar vÃ¡rios parÃ¢metros:

```json
{
    "data_url": "https://loteriascaixa-api.herokuapp.com/api/megasena",
    "data_file": null,
    "export_file": "output/historico_e_previsoes_megasena_v3.xlsx",
    "sequence_length": 20,                   
    "num_features_base": 60,
    "num_features_time": 60,
    "rolling_freq_windows": [10, 50, 100],
    "gru_units": 256,                     
    "use_batch_norm": true,              
    "dropout_rate": 0.45,               
    "epochs": 250,                    
    "batch_size": 64,                     
    "test_size_ratio": 0.15,
    "validation_split_ratio": 0.15,
    "cache_duration_hours": 24,
    "cache_dir": "output/cache",
    "tensorboard_log_dir": "output/logs/fit/",
    "test_hyperparameters": false
}
```

## ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, sinta-se Ã  vontade para:
1. Fazer um fork do projeto
2. Criar uma branch para sua feature
3. Fazer commit das mudanÃ§as
4. Abrir um Pull Request

## LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## Contato

Se vocÃª tiver dÃºvidas ou sugestÃµes, por favor abra uma issue no GitHub.

---

## ğŸ§  **AULA EXPLICATIVA: Como o GRU estÃ¡ sendo usado na previsÃ£o da Mega-Sena**

---

### ğŸ“Œ 1. **O que Ã© GRU (Gated Recurrent Unit)?**

**GRU** Ã© um tipo de rede neural recorrente (RNN) similar ao LSTM, mas com uma arquitetura mais simples.  
Ela tambÃ©m Ã© capaz de **"lembrar" informaÃ§Ãµes importantes ao longo do tempo**, usando portas (gates) para controlar o fluxo de informaÃ§Ã£o.

> **Exemplo de uso clÃ¡ssico:** PrevisÃ£o de sÃ©ries temporais, traduÃ§Ã£o automÃ¡tica, reconhecimento de fala, etc.

---

### ğŸ¯ **No seu projeto, a GRU estÃ¡ sendo usada para prever o PRÃ“XIMO sorteio da Mega-Sena com base em sorteios anteriores e features estatÃ­sticas.**

---

## ğŸ“¦ 2. **Como os dados sÃ£o estruturados**

Imagine a Mega-Sena como uma **sÃ©rie de eventos temporais**: cada sorteio Ã© um momento no tempo, com 6 dezenas sorteadas.

### âœ… Etapas de preparaÃ§Ã£o:

#### ğŸ”¹ a) One-Hot Encoding com `MultiLabelBinarizer`
Cada sorteio Ã© transformado em um vetor de 60 posiÃ§Ãµes (nÃºmeros de 1 a 60):
- Se o nÃºmero 5 foi sorteado, a posiÃ§Ã£o 5 recebe `1`.
- Se o nÃºmero 23 **nÃ£o** foi sorteado, a posiÃ§Ã£o 23 recebe `0`.

Exemplo:
```text
Sorteio: [5, 12, 18, 33, 45, 60]
Vetor:   [0, 0, 0, 0, 1, ..., 1]  â† 60 posiÃ§Ãµes
```

#### ğŸ”¹ b) Features EstatÃ­sticas
Para cada sorteio, calculamos:
- Contagem de nÃºmeros Ã­mpares
- Soma dos nÃºmeros
- Range (diferenÃ§a entre maior e menor nÃºmero)
- DistribuiÃ§Ã£o por zonas (4 zonas de 15 nÃºmeros)
- FrequÃªncia rolante em diferentes janelas (10, 50, 100 sorteios)

#### ğŸ”¹ c) Features Temporais
Para cada nÃºmero (1-60), calculamos:
- Quantos sorteios se passaram desde a Ãºltima apariÃ§Ã£o

---

#### ğŸ”¹ d) SequÃªncia de entrada (X) e alvo (y)

VocÃª usa uma **janela deslizante** para construir as sequÃªncias de entrada.  
Exemplo com `sequence_length = 15`:

| Entrada (X)                                       | Alvo (y)              |
|--------------------------------------------------|-----------------------|
| Sorteios 1-15 (15 vetores combinados)            | Sorteio 16 (vetor)    |
| Sorteios 2-16                                    | Sorteio 17            |
| ...                                              | ...                   |

Cada vetor de entrada combina:
- Vetor one-hot do sorteio
- Features temporais
- Features estatÃ­sticas

---

## ğŸ—ï¸ 3. **A Estrutura do Modelo GRU**

No seu cÃ³digo, a funÃ§Ã£o `build_model()` cria o modelo assim:

```python
model = Sequential()
model.add(Input(shape=(sequence_length, num_features_total)))
model.add(BatchNormalization())  # Opcional
model.add(GRU(192, return_sequences=True))
model.add(BatchNormalization())  # Opcional
model.add(Dropout(0.4))
model.add(GRU(96))  # Segunda camada GRU
model.add(BatchNormalization())  # Opcional
model.add(Dropout(0.4))
model.add(Dense(96, activation='relu'))
model.add(BatchNormalization())  # Opcional
model.add(Dropout(0.4))
model.add(Dense(60, activation='sigmoid'))
```

### ğŸ§© InterpretaÃ§Ã£o:
- **Input:** SequÃªncia de 15 sorteios anteriores com todas as features
- **GRU:** Processa a sequÃªncia e "lembra" de padrÃµes
- **BatchNorm:** Normaliza as ativaÃ§Ãµes entre camadas
- **Dropout:** Previne overfitting
- **Dense final:** Calcula a **probabilidade de cada nÃºmero (1 a 60)** aparecer no prÃ³ximo sorteio

---

## ğŸ§® 4. **Como Ã© feita a previsÃ£o**

ApÃ³s o treinamento:

- O modelo recebe a **Ãºltima sequÃªncia de sorteios com todas as features**
- Retorna 60 probabilidades (sigmoid output entre 0 e 1)
- Os **6 nÃºmeros com maiores probabilidades** sÃ£o selecionados como a "previsÃ£o"

Exemplo:
```python
predicted_indices = np.argsort(probabilidades)[-6:]
predicted_numbers = sorted((predicted_indices + 1).tolist())
```

---

## ğŸ“ˆ 5. **AvaliaÃ§Ã£o real do modelo**

VocÃª avalia o desempenho de duas formas:

### âœ”ï¸ AvaliaÃ§Ã£o TÃ©cnica:
- `Loss`: Erro da previsÃ£o (funÃ§Ã£o de perda binÃ¡ria)
- `Binary Accuracy`: Quantos bits acertou
- `AUC`: QuÃ£o bem o modelo diferencia 1s de 0s (nÃºmeros sorteados ou nÃ£o)

### âœ”ï¸ AvaliaÃ§Ã£o PrÃ¡tica (mais Ãºtil!):
- Compara os 6 nÃºmeros previstos com os sorteados reais
- Conta quantos acertos o modelo teve por sorteio
- Mostra a mÃ©dia e distribuiÃ§Ã£o de acertos
- Gera grÃ¡ficos de acertos ao longo do tempo

---

## ğŸ§ª 6. **LimitaÃ§Ãµes importantes**

- A Mega-Sena Ã© **aleatÃ³ria por definiÃ§Ã£o** (em teoria).
- Mesmo com redes neurais e features avanÃ§adas, nÃ£o hÃ¡ garantia de prever corretamente.
- Esse projeto Ã© **um exercÃ­cio de Machine Learning**, nÃ£o uma ferramenta infalÃ­vel para ganhar na loteria.

---

## âœ… ConclusÃ£o

| Etapa | O que faz |
|-------|-----------|
| 1. PrÃ©-processamento | Transforma sorteios em vetores e calcula features |
| 2. CriaÃ§Ã£o das sequÃªncias | ConstrÃ³i X (entrada) e y (alvo) |
| 3. Modelo GRU | Aprende padrÃµes temporais e estatÃ­sticos |
| 4. PrevisÃ£o | Gera 60 probabilidades, escolhe os 6 maiores |
| 5. AvaliaÃ§Ã£o | Mede acertos reais + mÃ©tricas de aprendizado |

---
